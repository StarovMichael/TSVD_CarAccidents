{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVcP1jSzqpuw",
        "outputId": "7b8c8c7f-40e6-4bd3-b60f-f98efe8716fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "(Reading database ... 126101 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.14+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.14+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark\n",
        "!pip install pyspark\n",
        "!apt-get install -qq openjdk-17-jdk-headless\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVYkfyuXqtBx",
        "outputId": "ebcdf772-6c82-4c77-efb7-5d54059f1ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BAi9-ozcqwj8"
      },
      "outputs": [],
      "source": [
        "import findspark, os\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"IG Calculation\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iN1NN64hqyVR"
      },
      "outputs": [],
      "source": [
        "train = spark.read.parquet('/content/drive/MyDrive/exports/dataset/train_selected_tree.parquet')\n",
        "test = spark.read.parquet(\"/content/drive/MyDrive/exports/dataset/test_selected.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_10J7taqz4x",
        "outputId": "fa3806b5-3f4b-4689-897f-2a65378280c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------+------+\n",
            "|Accident_Severity_ind| count|\n",
            "+---------------------+------+\n",
            "|                  0.0|208826|\n",
            "|                  1.0| 35039|\n",
            "|                  2.0|  4692|\n",
            "+---------------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.groupBy(\"Accident_Severity_ind\").count().orderBy(\"Accident_Severity_ind\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gjsJocjAq4pt"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        "    \"Local_Authority_(District)_ind\",\n",
        "    \"Casualty_Reference_ind\",\n",
        "    \"Police_Force_ind\",\n",
        "    \"Vehicle_Reference_Casualty_ind\"\n",
        "]\n",
        "\n",
        "train = train.drop(*columns_to_drop)\n",
        "test = test.drop(*columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lc2ibFjq1jf",
        "outputId": "19b6091f-7c2a-4dc9-d228-d77aef44b8e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Casualty_Severity_ind: double (nullable = true)\n",
            " |-- Casualty_Type_ind: double (nullable = true)\n",
            " |-- Vehicle_Manoeuvre_ind: double (nullable = true)\n",
            " |-- Number_of_Casualties_ind: double (nullable = true)\n",
            " |-- Speed_limit_ind: double (nullable = true)\n",
            " |-- Urban_or_Rural_Area_ind: double (nullable = true)\n",
            " |-- Did_Police_Officer_Attend_Scene_of_Accident_ind: double (nullable = true)\n",
            " |-- Junction_Detail_ind: double (nullable = true)\n",
            " |-- Vehicle_Leaving_Carriageway_ind: double (nullable = true)\n",
            " |-- Junction_Location_ind: double (nullable = true)\n",
            " |-- Vehicle_Type_ind: double (nullable = true)\n",
            " |-- Junction_Control_ind: double (nullable = true)\n",
            " |-- 1st_Point_of_Impact_ind: double (nullable = true)\n",
            " |-- Number_of_Vehicles_ind: double (nullable = true)\n",
            " |-- Light_Conditions_ind: double (nullable = true)\n",
            " |-- Hit_Object_off_Carriageway_ind: double (nullable = true)\n",
            " |-- Accident_Severity_ind: double (nullable = true)\n",
            " |-- classWeight: double (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Casualty_Severity_ind: double (nullable = true)\n",
            " |-- Casualty_Type_ind: double (nullable = true)\n",
            " |-- Vehicle_Manoeuvre_ind: double (nullable = true)\n",
            " |-- Number_of_Casualties_ind: double (nullable = true)\n",
            " |-- Speed_limit_ind: double (nullable = true)\n",
            " |-- Urban_or_Rural_Area_ind: double (nullable = true)\n",
            " |-- Did_Police_Officer_Attend_Scene_of_Accident_ind: double (nullable = true)\n",
            " |-- Junction_Detail_ind: double (nullable = true)\n",
            " |-- Vehicle_Leaving_Carriageway_ind: double (nullable = true)\n",
            " |-- Junction_Location_ind: double (nullable = true)\n",
            " |-- Vehicle_Type_ind: double (nullable = true)\n",
            " |-- Junction_Control_ind: double (nullable = true)\n",
            " |-- 1st_Point_of_Impact_ind: double (nullable = true)\n",
            " |-- Number_of_Vehicles_ind: double (nullable = true)\n",
            " |-- Light_Conditions_ind: double (nullable = true)\n",
            " |-- Hit_Object_off_Carriageway_ind: double (nullable = true)\n",
            " |-- Accident_Severity_ind: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.printSchema()\n",
        "test.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o8H3sJMMrCPw"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.sql import functions as F\n",
        "import numpy as np, math\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lDqdxVY-rNZA"
      },
      "outputs": [],
      "source": [
        "TARGET = \"Accident_Severity_ind\"\n",
        "train = train.withColumnRenamed(TARGET, \"label\")\n",
        "test  = test .withColumnRenamed(TARGET, \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v-Uk0Yf3rOz7"
      },
      "outputs": [],
      "source": [
        "#set numerical and categorical atributes\n",
        "\n",
        "numeric_columns = [\n",
        "    \"Number_of_Vehicles_ind\",\n",
        "    \"Number_of_Casualties_ind\",\n",
        "    \"Speed_limit_ind\",\n",
        "]\n",
        "\n",
        "service_cols = {\"label\", \"classWeight\"}\n",
        "categorical_columns = [c for c in train.columns\n",
        "                       if c not in numeric_columns and c not in service_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U3MCcOWVrldC"
      },
      "outputs": [],
      "source": [
        "# we use StringIndexer to sync metadata (numClasses) with actual data\n",
        "idx_cols = [c + \"_idx\" for c in categorical_columns]\n",
        "indexers = [StringIndexer(inputCol=c,\n",
        "                          outputCol=idx,\n",
        "                          handleInvalid=\"keep\")\n",
        "            for c, idx in zip(categorical_columns, idx_cols)]\n",
        "\n",
        "# we use OneHotEncoder to convert categories to vectors\n",
        "ohe_cols = [c + \"_ohe\" for c in categorical_columns]\n",
        "encoder  = OneHotEncoder(inputCols=idx_cols,\n",
        "                         outputCols=ohe_cols,\n",
        "                         handleInvalid=\"keep\")\n",
        "# VectorAssembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_columns + ohe_cols,\n",
        "    outputCol=\"features\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kdnV4UgBsPX_"
      },
      "outputs": [],
      "source": [
        "# multinomial Naive Bayes\n",
        "nb = NaiveBayes(\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    predictionCol=\"prediction\",\n",
        "    probabilityCol=\"probability\",\n",
        "    rawPredictionCol=\"rawPrediction\",\n",
        "    modelType=\"multinomial\",\n",
        "    weightCol=\"classWeight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UzGID1-asX_j"
      },
      "outputs": [],
      "source": [
        "pipe   = Pipeline(stages=indexers + [encoder, assembler, nb])\n",
        "nb_model = pipe.fit(train)\n",
        "preds_nb = nb_model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOgNbvlusbr_",
        "outputId": "4b02c404-202b-4bb7-d946-efb7080f5e04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (rows = true, cols = pred):\n",
            " [[109881   3275  24933]\n",
            " [  3412  13026   6364]\n",
            " [   261    240   2548]] \n",
            "\n",
            "Precision (macro): 0.6101\n",
            "Recall (macro): 0.7342\n",
            "F1-score (macro): 0.5579\n",
            "MCC : 0.4608\n"
          ]
        }
      ],
      "source": [
        "\n",
        "metric_rdd = (preds_nb\n",
        "              .select(\"prediction\", \"label\")\n",
        "              .rdd\n",
        "              .map(lambda r: (float(r[0]), float(r[1]))))\n",
        "\n",
        "metrics = MulticlassMetrics(metric_rdd)\n",
        "\n",
        "# confusion-matrix\n",
        "cm = metrics.confusionMatrix().toArray().astype(float)\n",
        "print(\"Confusion matrix (rows = true, cols = pred):\\n\", cm.astype(int), \"\\n\")\n",
        "\n",
        "# precision,recall, F1-score for each class\n",
        "labels = list(range(cm.shape[0]))\n",
        "\n",
        "precisions = [metrics.precision(l) for l in labels]\n",
        "recalls    = [metrics.recall(l)    for l in labels]\n",
        "f1s = [0. if (p + r) == 0 else 2*p*r/(p + r)\n",
        "       for p, r in zip(precisions, recalls)]\n",
        "\n",
        "# macro-average\n",
        "prec_macro   = float(np.mean(precisions))\n",
        "recall_macro = float(np.mean(recalls))\n",
        "f1_macro     = float(np.mean(f1s))\n",
        "\n",
        "print(f\"Precision (macro): {prec_macro:.4f}\")\n",
        "print(f\"Recall (macro): {recall_macro:.4f}\")\n",
        "print(f\"F1-score (macro): {f1_macro:.4f}\")\n",
        "\n",
        "# multi-class MCC \n",
        "\n",
        "c  = np.trace(cm)\n",
        "n  = cm.sum()\n",
        "p  = cm.sum(axis=0)\n",
        "t  = cm.sum(axis=1)\n",
        "\n",
        "num = (c * n) - np.dot(p, t)\n",
        "den = math.sqrt((n**2 - np.dot(p, p)) *\n",
        "                (n**2 - np.dot(t, t)))\n",
        "mcc = num / den if den else 0.0\n",
        "\n",
        "print(f\"MCC : {mcc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aliz3LESuKj_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
