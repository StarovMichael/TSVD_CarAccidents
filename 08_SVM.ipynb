{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgm06ZdUTaH9",
        "outputId": "5e83e380-383d-4c00-f49d-904c0f52690d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "(Reading database ... 126101 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.14+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.14+7-1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.14+7-1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n"
          ]
        }
      ],
      "source": [
        "!pip install findspark\n",
        "!pip install pyspark\n",
        "!apt-get install -qq openjdk-17-jdk-headless\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNzxpN6xThAa",
        "outputId": "e3a3a602-6603-45a8-d247-4ead2b3fe093"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DyHuj1FcTige"
      },
      "outputs": [],
      "source": [
        "import findspark, os\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"IG Calculation\") \\\n",
        "    .config(\"spark.executor.memory\", \"8g\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "N475ttG4TkJs"
      },
      "outputs": [],
      "source": [
        "train = spark.read.parquet('/content/drive/MyDrive/exports/dataset/train_selected_tree.parquet')\n",
        "test = spark.read.parquet(\"/content/drive/MyDrive/exports/dataset/test_selected.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj0oaI5uTmYa",
        "outputId": "75fb1d0c-7b54-4e11-e62a-89e61275eb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------+------+\n",
            "|Accident_Severity_ind| count|\n",
            "+---------------------+------+\n",
            "|                  0.0|208826|\n",
            "|                  1.0| 35039|\n",
            "|                  2.0|  4692|\n",
            "+---------------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.groupBy(\"Accident_Severity_ind\").count().orderBy(\"Accident_Severity_ind\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ebhSNTVKXnQ2"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = [\n",
        "    \"Local_Authority_(District)_ind\",\n",
        "    \"Casualty_Reference_ind\",\n",
        "    \"Police_Force_ind\",\n",
        "    \"Vehicle_Reference_Casualty_ind\"\n",
        "]\n",
        "\n",
        "train = train.drop(*columns_to_drop)\n",
        "test = test.drop(*columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_57DYoHXXpcZ"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "from pyspark.sql.functions import udf, col\n",
        "from pyspark.sql.types import DoubleType\n",
        "import numpy as np, math\n",
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXv01ezIa1jf",
        "outputId": "c12ef8b5-c8a0-43bc-f726-1ebbdf261b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Casualty_Severity_ind: double (nullable = true)\n",
            " |-- Casualty_Type_ind: double (nullable = true)\n",
            " |-- Vehicle_Manoeuvre_ind: double (nullable = true)\n",
            " |-- Number_of_Casualties_ind: double (nullable = true)\n",
            " |-- Speed_limit_ind: double (nullable = true)\n",
            " |-- Urban_or_Rural_Area_ind: double (nullable = true)\n",
            " |-- Did_Police_Officer_Attend_Scene_of_Accident_ind: double (nullable = true)\n",
            " |-- Junction_Detail_ind: double (nullable = true)\n",
            " |-- Vehicle_Leaving_Carriageway_ind: double (nullable = true)\n",
            " |-- Junction_Location_ind: double (nullable = true)\n",
            " |-- Vehicle_Type_ind: double (nullable = true)\n",
            " |-- Junction_Control_ind: double (nullable = true)\n",
            " |-- 1st_Point_of_Impact_ind: double (nullable = true)\n",
            " |-- Number_of_Vehicles_ind: double (nullable = true)\n",
            " |-- Light_Conditions_ind: double (nullable = true)\n",
            " |-- Hit_Object_off_Carriageway_ind: double (nullable = true)\n",
            " |-- Accident_Severity_ind: double (nullable = true)\n",
            " |-- classWeight: double (nullable = true)\n",
            "\n",
            "root\n",
            " |-- Casualty_Severity_ind: double (nullable = true)\n",
            " |-- Casualty_Type_ind: double (nullable = true)\n",
            " |-- Vehicle_Manoeuvre_ind: double (nullable = true)\n",
            " |-- Number_of_Casualties_ind: double (nullable = true)\n",
            " |-- Speed_limit_ind: double (nullable = true)\n",
            " |-- Urban_or_Rural_Area_ind: double (nullable = true)\n",
            " |-- Did_Police_Officer_Attend_Scene_of_Accident_ind: double (nullable = true)\n",
            " |-- Junction_Detail_ind: double (nullable = true)\n",
            " |-- Vehicle_Leaving_Carriageway_ind: double (nullable = true)\n",
            " |-- Junction_Location_ind: double (nullable = true)\n",
            " |-- Vehicle_Type_ind: double (nullable = true)\n",
            " |-- Junction_Control_ind: double (nullable = true)\n",
            " |-- 1st_Point_of_Impact_ind: double (nullable = true)\n",
            " |-- Number_of_Vehicles_ind: double (nullable = true)\n",
            " |-- Light_Conditions_ind: double (nullable = true)\n",
            " |-- Hit_Object_off_Carriageway_ind: double (nullable = true)\n",
            " |-- Accident_Severity_ind: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.printSchema()\n",
        "test.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCH3rNuAZesi",
        "outputId": "44bfab57-b00e-4224-c532-0882d58296bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+----------------------+------------------------+------------------+\n",
            "|summary|Number_of_Vehicles_ind|Number_of_Casualties_ind|Speed_limit_ind   |\n",
            "+-------+----------------------+------------------------+------------------+\n",
            "|min    |0.0                   |0.0                     |0.0               |\n",
            "|max    |2.0                   |2.0                     |2.0               |\n",
            "|mean   |0.514602284385473     |0.7264852729957314      |0.546104112939889 |\n",
            "|stddev |0.7209292729492647    |0.8195345470328419      |0.7159022083531436|\n",
            "+-------+----------------------+------------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "numeric_columns = [\n",
        "    \"Number_of_Vehicles_ind\",\n",
        "    \"Number_of_Casualties_ind\",\n",
        "    \"Speed_limit_ind\",\n",
        "]\n",
        "\n",
        "# to check if we need to scale\n",
        "stats = (train\n",
        "         .select(*[F.col(c).cast('double') for c in numeric_columns])\n",
        "         .summary('min', 'max', 'mean', 'stddev'))\n",
        "stats.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SEJYzDdodQun"
      },
      "outputs": [],
      "source": [
        "TARGET = \"Accident_Severity_ind\"\n",
        "train = train.withColumnRenamed(TARGET, 'label')\n",
        "test  = test .withColumnRenamed(TARGET, 'label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-ldkhJYQdXBd"
      },
      "outputs": [],
      "source": [
        "#set numerical and categorical atributes\n",
        "service_cols = {\"label\", \"classWeight\"}\n",
        "categorical_columns = [c for c in train.columns\n",
        "                       if c not in numeric_columns and c not in service_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "mjjK4PhVddl_"
      },
      "outputs": [],
      "source": [
        "# we use StringIndexer to sync metadata (numClasses) with actual data\n",
        "idx_cols = [c + \"_idx\" for c in categorical_columns]\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=c,\n",
        "                  outputCol=idx,\n",
        "                  handleInvalid=\"keep\")\n",
        "    for c, idx in zip(categorical_columns, idx_cols)\n",
        "]\n",
        "\n",
        "# we use OneHotEncoder to convert categories to vectors\n",
        "ohe_cols = [c + \"_ohe\" for c in categorical_columns]\n",
        "encoder  = OneHotEncoder(inputCols=idx_cols,\n",
        "                         outputCols=ohe_cols,\n",
        "                         handleInvalid=\"keep\")\n",
        "\n",
        "# VectorAssembler\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_columns + ohe_cols,\n",
        "    outputCol=\"features\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "WwFhBiACdjhc"
      },
      "outputs": [],
      "source": [
        "# build SVM and One-vs-Rest\n",
        "\n",
        "#base version detect only 2 classes, while we have 3\n",
        "base_svm = LinearSVC(\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    weightCol=\"classWeight\",\n",
        "    maxIter=100,\n",
        "    regParam=0.1\n",
        ")\n",
        "\n",
        "#we use OVR to build 3 versions \"0 vs rest\", \"1 vs rest\", \"2 vs rest\"  and take the one whose hyperplane gave the largest positive indentation\n",
        "ovr = OneVsRest(\n",
        "    classifier=base_svm,\n",
        "    labelCol=\"label\",\n",
        "    featuresCol=\"features\",\n",
        "    weightCol=\"classWeight\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "SiICEqyhdmcq"
      },
      "outputs": [],
      "source": [
        "pipe = Pipeline(stages=indexers + [encoder, assembler, ovr])\n",
        "model = pipe.fit(train)\n",
        "preds = model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyyWuf-Ndop0",
        "outputId": "7c942cf8-5934-4ecb-ef00-8a46353e3c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix (rows = true, cols = pred):\n",
            " [[135721    129   2239]\n",
            " [  5968  16036    798]\n",
            " [   620    574   1855]] \n",
            "\n",
            "Precision (macro): 0.7636\n",
            "Recall (macro): 0.7648\n",
            "F1-score (macro): 0.7488\n",
            "MCC : 0.7571\n"
          ]
        }
      ],
      "source": [
        "metric_rdd = (preds\n",
        "              .select(\"prediction\", \"label\")\n",
        "              .rdd\n",
        "              .map(lambda r: (float(r[0]), float(r[1]))))\n",
        "\n",
        "metrics = MulticlassMetrics(metric_rdd)\n",
        "\n",
        "# confusion-matrix\n",
        "cm = metrics.confusionMatrix().toArray().astype(float)\n",
        "print(\"Confusion matrix (rows = true, cols = pred):\\n\", cm.astype(int), \"\\n\")\n",
        "\n",
        "# precision,recall, F1-score for each class\n",
        "labels = list(range(cm.shape[0]))\n",
        "\n",
        "precisions = [metrics.precision(l) for l in labels]\n",
        "recalls    = [metrics.recall(l)    for l in labels]\n",
        "f1s = [0. if (p + r) == 0 else 2*p*r/(p + r)\n",
        "       for p, r in zip(precisions, recalls)]\n",
        "\n",
        "# macro-average\n",
        "prec_macro   = float(np.mean(precisions))\n",
        "recall_macro = float(np.mean(recalls))\n",
        "f1_macro     = float(np.mean(f1s))\n",
        "\n",
        "print(f\"Precision (macro): {prec_macro:.4f}\")\n",
        "print(f\"Recall (macro): {recall_macro:.4f}\")\n",
        "print(f\"F1-score (macro): {f1_macro:.4f}\")\n",
        "\n",
        "# multi-class MCC\n",
        "\n",
        "c  = np.trace(cm)\n",
        "n  = cm.sum()\n",
        "p  = cm.sum(axis=0)\n",
        "t  = cm.sum(axis=1)\n",
        "\n",
        "num = (c * n) - np.dot(p, t)\n",
        "den = math.sqrt((n**2 - np.dot(p, p)) *\n",
        "                (n**2 - np.dot(t, t)))\n",
        "mcc = num / den if den else 0.0\n",
        "\n",
        "print(f\"MCC : {mcc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0MwPXZ1s761"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
